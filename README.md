ğŸ–¼ï¸ Making Text Like It's 1700 Again â€” with Deep Learning
This project started as an exploration:
"Can we take modern digital text and make it look like it was printed in the Renaissanceâ€¦ without destroying readability?"

Turns outâ€”yes, yes we can.

ğŸ¯ Whatâ€™s This About?
Weâ€™re applying neural style transfer to text pages to make them look like Renaissance-era printed materialâ€”aged paper, rich brush strokes, imperfect printingâ€”but the text is still readable.
This is achieved by blending the stylized result with the original content using some simple math and a little TensorFlow magic.
Everything runs on Google Colab. No GPUs, no fancy servers, just a laptop and the cloud.
ğŸ§© The Pipeline
â€¢	Hereâ€™s the full flow:

â€¢	ğŸ“ Start with a `.docx` file - Itâ€™s converted to PDF and then split into individual page images.
â€¢	ğŸ¨ Apply Renaissance flair - We pull in some Renaissance-style paintings and use TensorFlow Hubâ€™s neural style transfer model to give each page a makeover.
â€¢	ğŸ§ª Blend, donâ€™t obliterate - We mix the stylized image with the original using an alpha factor so you get the texture and feelâ€”without losing the text.
â€¢	ğŸ’¾ Save it like itâ€™s precious art - All stylized and blended outputs are neatly saved into folders you can download.
ğŸ”§ Tech Stack
- Python + Google Colab
- TensorFlow Hub (arbitrary-image-stylization-v1-256)
- Pillow (PIL), NumPy, pdf2image
- LibreOffice (for .docx â†’ .pdf)
ğŸ“ Folder Structure

Untitled42.ipynb              # Main notebook (runs end-to-end)
docx.pdf                      # Converted from .docx
docx_pages/                   # PNGs of each page
renaissance_dataset/         # style images
stylized_output/             # Style-transferred results
blended_output/              # Final results with preserved text

ğŸš€To Run It Yourself
Upload your `.docx` file, and run the notebook.

To download the results:

!zip -r results.zip renaissance_dataset docx.pdf stylized_output blended_output
from google.colab import files
files.download('results.zip')

ğŸŒ±Diffusion & GAN Ideas
I also explored the idea of generating ink-bleed and degradation effects using:
- A small diffusion model trained on text degradation pairs
- Possibly CycleGAN (if more unsupervised data is available)

Too heavy for a laptop right now, but itâ€™s all part of the vision.
ğŸ§  Final Thoughts
This was a fun experiment in style transfer that balances aesthetics with utility.
It blends art and AI in a literal wayâ€”and there's a lot of room to grow from here.


